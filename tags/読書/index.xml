<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>読書 on @uyorumの雑記帳</title>
    <link>https://blog.uyorum.net/tags/%E8%AA%AD%E6%9B%B8/</link>
    <description>Recent content in 読書 on @uyorumの雑記帳</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>uyorum All Right Reserved.</copyright>
    <lastBuildDate>Thu, 29 Jun 2017 21:52:49 +0900</lastBuildDate><atom:link href="https://blog.uyorum.net/tags/%E8%AA%AD%E6%9B%B8/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Infrastructure as Code 感想 (6-9章)</title>
      <link>https://blog.uyorum.net/post/infrastructure-as-code-chap6-9/</link>
      <pubDate>Thu, 29 Jun 2017 21:52:49 +0900</pubDate>
      
      <guid>https://blog.uyorum.net/post/infrastructure-as-code-chap6-9/</guid>
      <description>オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
6~9章は各領域での設計パターンやプラクティスを整理している
サーバーのプロビジョニング サーバーに含まれるもの ソフトウェア 構成/設定 データ ログもここに含まれる インフラストラクチャはサーバのアップデート，交換，削除のプロセスを通して，一貫して「データ」へのアクセス性を提供しなければならない プロセスのさまざまな部分にかかる時間を計測するようにしなければならない これはいろんなところに言えそう．次からは時間を計測することを考えるようにしようと思う サーバーのテンプレート管理 構築方法 原始イメージでサーバーを作成し設定を変更する ほかのサーバーに原始イメージディスクをマウントし変更を加える chrootを使う ブート，シャットダウンの時間を省略できる テンプレート上にログが作成されないのでわざわざ削除する必要がない Netflix/aminator: A tool for creating EBS AMIs. This tool currently works for CentOS/RedHat Linux images and is intended to run on an EC2 instance. このやり方は思い付かなかった テンプレート自体にもバージョン番号を付け，各サーバーがどのテンプレートから作成されたか追跡できるようにする テンプレートをアップデートしたら既存のサーバーも作成しなおせ，さもないと構成ドリフトが発生する これをやるのはすごく難しいと思うのだが．サービスを停止せずにサーバーを入れ替えなければならない テンプレートに変更を加えたら既存サーバーにも同じ変更を加えるようにするのが妥協ラインかな… サーバーのアップデート/変更 プッシュ同期 プル同期 変更後のテストもサーバーから自発的に実行できる必要がある？ サーバー上で動かしても問題なさそう：aelsabbahy/goss: Quick and Easy server testing/validation あるいはモニタリングにまかせる 異常が起こった場合の切り戻しはどうやってトリガーする？ マスターレス構成管理 SPoFがなくなる サーバー作成直後の設定とサーバーのアップデートは必ずしも同一の仕組みとは限らない，という前提でこの本は書かれている気がする インフラストラクチャ定義 適切なスタックにインフラを分割し，定義，実装する 人々が変更を加えるのを恐れるようになったら，インフラストラクチャ定義がモノリシックになってきていると考えることができる スタックの共有(DBサーバの共有など)は避けるべき 5章で説明された通りどうしても共有されるサービスは存在する．その場合はサービスレベルを定める アプリケーションコードとインフラストラクチャコードを統一的に管理する Googleのような巨大リポジトリでの開発には，呼び出し先の変更と同時に呼び出し元も変更できるという利点がある．1 これと似たような考え方か． 既存の設計パターンを当てはめようとすると，かえって複雑になる場合がある．設計を見直すことも必要 管理しやすようにやり方を変える．手段と目的が逆転してるように感じるが大事 参考文献 Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017 Infrastructure as Code ―クラウドにおけるサーバ管理の原則とプラクティス amazon.</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (5章)</title>
      <link>https://blog.uyorum.net/post/infrastructure-as-code-chap5/</link>
      <pubDate>Wed, 21 Jun 2017 22:47:39 +0900</pubDate>
      
      <guid>https://blog.uyorum.net/post/infrastructure-as-code-chap5/</guid>
      <description>オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
インフラストラクチャサービス，ツールが満たすべき条件 外部定義を使えるツールを選ぶ DBに設定を保持するツールはどうすればいいか 設定をyamlなどで構造化してテキストに保存．それを読み込んでAPIを発行，サービスへ設定を反映させる．確実に両者が同一の内容であることを確信するいは逆(サービスからyamlへ)もできる必要がある インポート/エクスポートを使う．(エクスポートした設定情報は大抵は人間が読むようにはできていない．独自のフォーマットで書かれていて容易にパースできない) (本に書いてある例)SeleniumのようなものでGUIを操作する いずれにしても辛そう．よほどのことがない限りそのようなツールは選択すべきでない インフラストラクチャがダイナミックだという前提で作られたツールを選ぶ サービス自身とサービスが管理するものの変化に柔軟に自動的に追従，対処できるもの ライセンスがクラウド互換になっている製品を選ぶ ここでは主に柔軟性に関するもの 疎結合をサポートする製品を選ぶ チーム間でのサービスの共有 チーム間で共有される可能性のあるサービス モニタリング，CI，バグ追跡(BTS？)，DNS，アーティファクトリポジトリ(構成レジストリ？) それを使うチームの要件，使われ方の特性などが様々になり，それ自体が小さなパブリックサービスのようにみなせるかもしれない それぞれサービスレベルやサービス仕様を定めてチームに使ってもらう ふつうにマイクロサービスアーキテクチャの考え方みたい モニタリング モニタリングの目標は，必要とする人に必要なときに適切な情報を提供すること つまり，モニタリングシステムの設計を始める前に想定ユーザを決めるフェーズがあるということ．今までは考えたことなかった 個々のイベントは問題ないが，それが頻発する場合は問題がある可能性がある場合，頻度に関する閾値を設ける (a)日常の仕事を続行する，(b)大声を出して今していることを中断し，対策に乗り出す どちらを取るべきかをすぐに判断できるようなのでなければならない 複数のサーバーに関連性があることを自動的にタギングしなければならない Zabbixでもネットワークディスカバリ，ローレベルディスカバリ，AgentのUserParameterあたりを使えば自動でタギングできるが，ダッシュボードを動的に生成できないのが辛い つまりZabbixはInfrastructure as Codeに適していない DataDogやMackerel(おそらくNewRelicも)はこのへんの考え方が前提になってる Prometheusはこのあたりどうなんだろう．Grafanaと組み合わせれば普通にできそう(それを言えばZabbixでもいいのだが) サービスディスカバリ サーバーサイドサービスディスカバリ ロードバランサが結局ボトルネックになったりする クライアントサイドサービスディスカバリ 通常，こちらの方がアプリケーションは複雑になる アプリケーションのlocalhostにロードバランサを用意すればいろいろ解決しそう 参考文献 Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017 Infrastructure as Code ―クラウドにおけるサーバ管理の原則とプラクティス amazon.co.jp </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (4章)</title>
      <link>https://blog.uyorum.net/post/infrastructure-as-code-chap4/</link>
      <pubDate>Sat, 17 Jun 2017 18:17:36 +0900</pubDate>
      
      <guid>https://blog.uyorum.net/post/infrastructure-as-code-chap4/</guid>
      <description>&lt;p&gt;オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．&lt;strong&gt;太字は自分の感想&lt;/strong&gt;， &lt;em&gt;斜字体は本からの引用&lt;/em&gt; ，そのほかは本の要約など．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (3章)</title>
      <link>https://blog.uyorum.net/post/infrastructure-as-code-chap3/</link>
      <pubDate>Thu, 15 Jun 2017 23:14:55 +0900</pubDate>
      
      <guid>https://blog.uyorum.net/post/infrastructure-as-code-chap3/</guid>
      <description>オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
ツールの要件 他のツールを連携しやすいこと コマンドライン引数や環境変数などでの入力，パースしやすい結果出力 設定の外在化 自動実行しやすいこと 冪等性など 失敗したらわかる 周辺のツールとの連携しやすさは意識して考慮に入れてなかった 考え方はすごくよくわかる．UNIX哲学に通じている 構成レジストリ コンフィグ定義ツールが提供するもの(Chef Server, Ansible Towerなど) Zookeeper/Consul/etcd プログラムによるレジストリエントリの追加，更新，削除をサポートしていること こういうのほしいと前から思っていたけどどうやって実装すればいいか，定義ツールとどう連携させればいいかイメージついてない 軽い構成レジストリ S3やVCS上のファイル HTTP等で配布．こうすることで可用性，スケーリングしやすい．管理が単純 頻繁に更新されて複雑になる部分は分割やシャーディングで対応する こうした場合，例えばAnsibleへはどうやって渡せばいいんだろうか ansible-playbook実行前にyaml組んでvar_fileなどに渡す ダイナミックインベントリみたいなことはできなさそう．一回ファイルに吐き出す必要がある？ json組み立ててansible-playbookの--extra-varsオプションに渡す Ansible TowerのAPIでも渡せるかも Consumer Driven Contract Testing Itamaeのnode.validate!はまさにこれだと思う1 こんな記事出てきた Consumer-Driven Contracts: A Service Evolution Pattern Pactのようなツールで容易に書けそう CMDB CMDBとInfrastructure as Codeは構成管理に対するアプローチが正反対．両者を同一視してはならない ただしすべてを自動化するならInfrastructure as CodeはCMDBを兼ねることができる．またはInfrastructure as CodeがCMDBも管理することができる ハードウェアも含めてすべてを自動化はけっこうハードル高そう その他 インフラを完全に管理，自動化するために，やり方を変えるだけでなく自動化しやすいようにタスクそのものを見直すメンタルを忘れてはいけない 以上
参考文献 Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017 Infrastructure as Code ―クラウドにおけるサーバ管理の原則とプラクティス amazon.</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (2章)</title>
      <link>https://blog.uyorum.net/post/infrastructure-as-code-chap2/</link>
      <pubDate>Mon, 12 Jun 2017 20:48:25 +0900</pubDate>
      
      <guid>https://blog.uyorum.net/post/infrastructure-as-code-chap2/</guid>
      <description>オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
ダイナミックインフラストラクチャの要件 NISTのクラウドの要件より広い． 「オンプレミスで，ただひとつのシステムを稼動させるためのインフラ」も考慮に入れているからだろう プラットフォームから提供されるリソース 計算リソース ストレージリソース ブロックストレージ オブジェクトストレージ ネットワーク化されたファイルシステム NFS，SMB これらのテクノロジは，サーバーが頻繁に追加，削除されるような環境にはうまく適合しない GlusterFS，HDFS，Ceph 上記の課題に対応できるよう設計されているが，自分の環境でそれがうまくいっていることをきちんとテストすることが重要 代わりにアプリケーションレベルやブロックレベルのレプリケーションで事足りる場合もある ネットワークリソース 特定のデバイスが高価過ぎて，チームがテストインスタンスを確保できない場合がある．そのような状況に置かれたチームは，優先順位を考えてもっと安いデバイスを使うようにすべきだ 確かに，結局のところ同じハードを同じだけ用意しないとテストできないのだが，そのために使うデバイスを安いものにしろ，という言説は初めて見た．だいたいは仮想化してお茶を濁すのに． 独自クラウドを構築するためのトータルコスト 既存のインフラ，データセンター，知識にかけたコストも自前のホスティングを続ける理由としてよく挙げられる．(中略) しかし，これはサンクコストの呪縛というものだ． クラウドのポータビリティ クラウドインフラへの移行を計画するときによく浮上する要件のひとつに，ひとつのクラウドベンダーによる囲い込みを避けるというものがある．(中略) しかし，この要件に時間と金を注ぎ込みすぎないよう注意しなければならない 確かに，クラウドの一部の機能をサードパーティ製のツールで置き換えたところで依然として移行のコストは大きいし，だいたいの場合は運用のコストが上がる あるクラウドでのやり方が(将来にわたって)それが別のクラウドでそのまま利用できるとは限らない 例えば，TerraformでEC2とGCEにインスタンスを作るだけで全く文法が違う(Terraformの批判をしているわけではない) クラウドやツールが将来仕様変更をするかもしれないし サードパーティ製のものを使うことでよりよりワークフローを得られる可能性がある場合は検討すべき(CodeCommitとCodeBuildの代わりにGithubとTravisCIとか) 自動テストプロセスを継続して維持・使用することで，自信をもって移行を実施できるようにしておくのが現実的な方策 クラウドと仮想マシンに対するマシンレベルの共感 そのプラットフォームで最大のパフォーマンスを引き出すための話？ 必要性は分かるが，ポータビリティとは真逆の話に見える あまりにそのクラウドに最適化してしまうとポータビリティを落とす要因になりそう オンプレの場合でも，構成に応じて最適化しつつそれらを管理するのは大変そう．妥協して汎用的なサーバーを横に並べる形になりそう 参考文献 Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017 Infrastructure as Code ―クラウドにおけるサーバ管理の原則とプラクティス amazon.co.jp </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (1章)</title>
      <link>https://blog.uyorum.net/post/infrastructure-as-code-chap1/</link>
      <pubDate>Sun, 11 Jun 2017 19:05:42 +0900</pubDate>
      
      <guid>https://blog.uyorum.net/post/infrastructure-as-code-chap1/</guid>
      <description>オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
Infrastructure as Codeの目標 ざっくり言うと「(頻繁な)変化に柔軟に対応できるようになること」ということかなと思った そのために システム変更が日常茶飯事の出来事になること 失敗を完全に防ぐという前提は捨てる．失敗しても素早く修正できるようになることを目指す 反復的なタスクは自動化すること 継続的な改善をすること 会議やドキュメントでソリューションを論ずることなく，実装，テスト，計測を通じてソリューションの効果が証明できるようになること Infrastructure as Codeでこれを目指す，というのがピンと来なかった 課題 サーバースプロール，構成ドリフト，スノーフレークサーバーは自分の環境ではほとんどないかな いちおうChefを使っている ロールごとにVMを作成して役割が混ざらないようにしている オートメーション恐怖症…これはある サーバーに統一性がない→オートメーションにより何かが壊れないかが心配→オートメーションツールの外で変更を加える→… の悪循環 この循環から抜けるには「自動化された変更」のリリースプロセスの確立とテストの充実が必要になると最近は考えている 「この変更」を「この方法」で適用するのは安全である，と自動的に言えるようになればいい ペットから家畜へ 数年前からよく聞くようになった サーバ名にテーマを設け，自分がプロビジョニングした新しいサーバーの名前をじっくり考えていた時代が懐しい．しかし，担当するすべてのサーバーを手作業で調整し，サーバーのご期限をうかがわなけれあならなかった時代は懐しくない おもしろい 統一的なシステム 一部のサーバーでより大きなディスクが必要になった場合 すべてのサーバーを同じように拡張する xl-file-serverのような新しいロールを追加する 自分だと深く考えずに(ロールを分けずに)そのサーバーだけ拡張してしまいそうだと思った(ディスクサイズだけ変数化しておけばいいじゃん) その些細な差異が積み重なって管理システムと人に負荷を与えることになる．気をつけたい 反復的なシステム 「パーティションの分割」のような些細なタスクであろうとも，手動でやってしまうと差異が生じる可能性がある． サイズ，ファイルシステム，そのパラメータ etc. スクリプトで実行できるシステムはかならずスクリプトにする そして，将来同様のタスクをするとになったときにそのスクリプトを使う ←これが難しい．スクリプトを書くだけでなく管理システムに組み込まなければならない スクリプトにするのが難しい場合は問題を掘り下げて，役に立つテクニックやツールがないか，別の方法がないかを検討する 継続的にサービスを利用可能状態に保つ 永続化が必要なデータの定義を広げることが大切．通常はアプリケーションの構成/設定，ログファイルなども保護対象に含める サーバーを家畜のように扱うことを前提に，サーバー上のほとんどの情報はいつ失われてもよい状態にしておくということか 参考文献 Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017 Infrastructure as Code ―クラウドにおけるサーバ管理の原則とプラクティス amazon.co.jp </description>
    </item>
    
  </channel>
</rss>
