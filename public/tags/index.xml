<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>@uyorumの雑記帳</title>
    <link>http://uyorum.github.io/tags/</link>
    <description>Recent content on @uyorumの雑記帳</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>uyorum All Right Reserved.</copyright>
    <lastBuildDate>Sat, 02 Sep 2017 10:41:35 +0900</lastBuildDate>
    
	<atom:link href="http://uyorum.github.io/tags/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ESP32とMongooseOSを使ってTSL2561で照度を取得する(実装編)</title>
      <link>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-02/</link>
      <pubDate>Sat, 02 Sep 2017 10:41:35 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-02/</guid>
      <description>前回の続き． Mongoose OSの設定とTSL2561を使うためのコードを書いていく．
設計 今回は1分ごとにTSL2561で照度を取得し，MQTTで値をPublishすることにする． 細かいパラメータ等は以下のようにする．
TSL2561 前回参考にした記事1でも説明されている通り，TSL2561にはGainとIntegration Timeという設定項目がある． 本来は，使用する環境下で想定される照度に合わせて適切な値を選択するか現在の照度に応じて自動で調整すべきものである． 今回はひとまず，それぞれデフォルト値で使用する．
 Gain: 1x Integration Time: 402ms Scale: (16 / Gain) * (402 / Integration Time) = 16  MQTT 今回は自分で立てたBrokerを使う．Topicは任意だがこの記事内では以下のようにする．
 ホスト名: broker.example.com:1883 認証: なし Topic: home/brightness QoS: 0  センサーの接続 I2Cデバイスのピンをどのピンに接続すればよいのかわからずにここで結構時間を使った． mosで起動するMongoose OSのWeb UIからDevice Config→Expert ViewからI2Cようの設定を見ることができる．自分の環境ではデフォルトで以下のようになっていた． sda端子を32ピン，scl端子を33ピンに接続すればよいことがわかる．
&amp;quot;i2c&amp;quot;: { &amp;quot;enable&amp;quot;: true, &amp;quot;freq&amp;quot;: 100000, &amp;quot;debug&amp;quot;: false, &amp;quot;sda_gpio&amp;quot;: 32, &amp;quot;scl_gpio&amp;quot;: 33 },  その他にVinを3.3V端子，GNDを適当なGNDピンに接続した．
MQTTの設定 Brokerと認証の設定を行う． Device Config→Simple View→MQTT Settingsで設定を行うのがおそらく最も簡単．</description>
    </item>
    
    <item>
      <title>ESP32とMongooseOSを使ってTSL2561で照度を取得する(実装編)</title>
      <link>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-02/</link>
      <pubDate>Sat, 02 Sep 2017 10:41:35 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-02/</guid>
      <description>前回の続き． Mongoose OSの設定とTSL2561を使うためのコードを書いていく．
設計 今回は1分ごとにTSL2561で照度を取得し，MQTTで値をPublishすることにする． 細かいパラメータ等は以下のようにする．
TSL2561 前回参考にした記事1でも説明されている通り，TSL2561にはGainとIntegration Timeという設定項目がある． 本来は，使用する環境下で想定される照度に合わせて適切な値を選択するか現在の照度に応じて自動で調整すべきものである． 今回はひとまず，それぞれデフォルト値で使用する．
 Gain: 1x Integration Time: 402ms Scale: (16 / Gain) * (402 / Integration Time) = 16  MQTT 今回は自分で立てたBrokerを使う．Topicは任意だがこの記事内では以下のようにする．
 ホスト名: broker.example.com:1883 認証: なし Topic: home/brightness QoS: 0  センサーの接続 I2Cデバイスのピンをどのピンに接続すればよいのかわからずにここで結構時間を使った． mosで起動するMongoose OSのWeb UIからDevice Config→Expert ViewからI2Cようの設定を見ることができる．自分の環境ではデフォルトで以下のようになっていた． sda端子を32ピン，scl端子を33ピンに接続すればよいことがわかる．
&amp;quot;i2c&amp;quot;: { &amp;quot;enable&amp;quot;: true, &amp;quot;freq&amp;quot;: 100000, &amp;quot;debug&amp;quot;: false, &amp;quot;sda_gpio&amp;quot;: 32, &amp;quot;scl_gpio&amp;quot;: 33 },  その他にVinを3.3V端子，GNDを適当なGNDピンに接続した．
MQTTの設定 Brokerと認証の設定を行う． Device Config→Simple View→MQTT Settingsで設定を行うのがおそらく最も簡単．</description>
    </item>
    
    <item>
      <title>ESP32とMongooseOSを使ってTSL2561で照度を取得する(準備編)</title>
      <link>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-01/</link>
      <pubDate>Wed, 02 Aug 2017 20:53:04 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-01/</guid>
      <description>&lt;p&gt;かねてから触ってみたいと思っていたMongooseOSと以前買ったTSL2561照度センサーモジュールがあったのでESP32にMongooseOSを入れて照度を取得してみようと思った．&lt;br /&gt;
そもそもI2Cデバイスを触るのが初めてだったため、いきなりMongooseOSでそれを扱おうとするのはハードルが高すぎると考え、まずはその準備編として情報の多いRaspberryPiで照度を取得してみることにした．&lt;br /&gt;
最後にESP32へのMongooseOSのインストールも行っておく．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ESP32とMongooseOSを使ってTSL2561で照度を取得する(準備編)</title>
      <link>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-01/</link>
      <pubDate>Wed, 02 Aug 2017 20:53:04 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/tsl2561-with-mongoose-os-on-esp32-01/</guid>
      <description>&lt;p&gt;かねてから触ってみたいと思っていたMongooseOSと以前買ったTSL2561照度センサーモジュールがあったのでESP32にMongooseOSを入れて照度を取得してみようと思った．&lt;br /&gt;
そもそもI2Cデバイスを触るのが初めてだったため、いきなりMongooseOSでそれを扱おうとするのはハードルが高すぎると考え、まずはその準備編として情報の多いRaspberryPiで照度を取得してみることにした．&lt;br /&gt;
最後にESP32へのMongooseOSのインストールも行っておく．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fitbit Charge2用サードパーティ製バンドを買った</title>
      <link>http://uyorum.github.io/blog/fitbit-charge2-bands/</link>
      <pubDate>Mon, 03 Jul 2017 21:10:46 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/fitbit-charge2-bands/</guid>
      <description>&lt;p&gt;今年の2月末に購入したFitbit Charge2のバンドのゴムがコネクタ部分から浮いてきてしまった．使用上は問題ないのだが気になってしまうので替えのバンドを購入した．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fitbit Charge2用サードパーティ製バンドを買った</title>
      <link>http://uyorum.github.io/blog/fitbit-charge2-bands/</link>
      <pubDate>Mon, 03 Jul 2017 21:10:46 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/fitbit-charge2-bands/</guid>
      <description>&lt;p&gt;今年の2月末に購入したFitbit Charge2のバンドのゴムがコネクタ部分から浮いてきてしまった．使用上は問題ないのだが気になってしまうので替えのバンドを購入した．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (6-9章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap6-9/</link>
      <pubDate>Thu, 29 Jun 2017 21:52:49 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap6-9/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
6~9章は各領域での設計パターンやプラクティスを整理している
サーバーのプロビジョニング  サーバーに含まれるもの  ソフトウェア 構成/設定 データ  ログもここに含まれる   インフラストラクチャはサーバのアップデート，交換，削除のプロセスを通して，一貫して「データ」へのアクセス性を提供しなければならない プロセスのさまざまな部分にかかる時間を計測するようにしなければならない  これはいろんなところに言えそう．次からは時間を計測することを考えるようにしようと思う   サーバーのテンプレート管理  構築方法  原始イメージでサーバーを作成し設定を変更する ほかのサーバーに原始イメージディスクをマウントし変更を加える  chrootを使う ブート，シャットダウンの時間を省略できる テンプレート上にログが作成されないのでわざわざ削除する必要がない Netflix/aminator: A tool for creating EBS AMIs. This tool currently works for CentOS/RedHat Linux images and is intended to run on an EC2 instance. このやり方は思い付かなかった   テンプレート自体にもバージョン番号を付け，各サーバーがどのテンプレートから作成されたか追跡できるようにする テンプレートをアップデートしたら既存のサーバーも作成しなおせ，さもないと構成ドリフトが発生する  これをやるのはすごく難しいと思うのだが．サービスを停止せずにサーバーを入れ替えなければならない テンプレートに変更を加えたら既存サーバーにも同じ変更を加えるようにするのが妥協ラインかな…   サーバーのアップデート/変更  プッシュ同期 プル同期  変更後のテストもサーバーから自発的に実行できる必要がある？  サーバー上で動かしても問題なさそう：aelsabbahy/goss: Quick and Easy server testing/validation あるいはモニタリングにまかせる  異常が起こった場合の切り戻しはどうやってトリガーする？  マスターレス構成管理  SPoFがなくなる  サーバー作成直後の設定とサーバーのアップデートは必ずしも同一の仕組みとは限らない，という前提でこの本は書かれている気がする  インフラストラクチャ定義  適切なスタックにインフラを分割し，定義，実装する 人々が変更を加えるのを恐れるようになったら，インフラストラクチャ定義がモノリシックになってきていると考えることができる スタックの共有(DBサーバの共有など)は避けるべき  5章で説明された通りどうしても共有されるサービスは存在する．その場合はサービスレベルを定める  アプリケーションコードとインフラストラクチャコードを統一的に管理する  Googleのような巨大リポジトリでの開発には，呼び出し先の変更と同時に呼び出し元も変更できるという利点がある．1 これと似たような考え方か．  既存の設計パターンを当てはめようとすると，かえって複雑になる場合がある．設計を見直すことも必要  管理しやすようにやり方を変える．手段と目的が逆転してるように感じるが大事   参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017   Google の巨大レポジトリとブランチ無し運用 - Kato Kazuyoshi [return]   </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (6-9章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap6-9/</link>
      <pubDate>Thu, 29 Jun 2017 21:52:49 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap6-9/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
6~9章は各領域での設計パターンやプラクティスを整理している
サーバーのプロビジョニング  サーバーに含まれるもの  ソフトウェア 構成/設定 データ  ログもここに含まれる   インフラストラクチャはサーバのアップデート，交換，削除のプロセスを通して，一貫して「データ」へのアクセス性を提供しなければならない プロセスのさまざまな部分にかかる時間を計測するようにしなければならない  これはいろんなところに言えそう．次からは時間を計測することを考えるようにしようと思う   サーバーのテンプレート管理  構築方法  原始イメージでサーバーを作成し設定を変更する ほかのサーバーに原始イメージディスクをマウントし変更を加える  chrootを使う ブート，シャットダウンの時間を省略できる テンプレート上にログが作成されないのでわざわざ削除する必要がない Netflix/aminator: A tool for creating EBS AMIs. This tool currently works for CentOS/RedHat Linux images and is intended to run on an EC2 instance. このやり方は思い付かなかった   テンプレート自体にもバージョン番号を付け，各サーバーがどのテンプレートから作成されたか追跡できるようにする テンプレートをアップデートしたら既存のサーバーも作成しなおせ，さもないと構成ドリフトが発生する  これをやるのはすごく難しいと思うのだが．サービスを停止せずにサーバーを入れ替えなければならない テンプレートに変更を加えたら既存サーバーにも同じ変更を加えるようにするのが妥協ラインかな…   サーバーのアップデート/変更  プッシュ同期 プル同期  変更後のテストもサーバーから自発的に実行できる必要がある？  サーバー上で動かしても問題なさそう：aelsabbahy/goss: Quick and Easy server testing/validation あるいはモニタリングにまかせる  異常が起こった場合の切り戻しはどうやってトリガーする？  マスターレス構成管理  SPoFがなくなる  サーバー作成直後の設定とサーバーのアップデートは必ずしも同一の仕組みとは限らない，という前提でこの本は書かれている気がする  インフラストラクチャ定義  適切なスタックにインフラを分割し，定義，実装する 人々が変更を加えるのを恐れるようになったら，インフラストラクチャ定義がモノリシックになってきていると考えることができる スタックの共有(DBサーバの共有など)は避けるべき  5章で説明された通りどうしても共有されるサービスは存在する．その場合はサービスレベルを定める  アプリケーションコードとインフラストラクチャコードを統一的に管理する  Googleのような巨大リポジトリでの開発には，呼び出し先の変更と同時に呼び出し元も変更できるという利点がある．1 これと似たような考え方か．  既存の設計パターンを当てはめようとすると，かえって複雑になる場合がある．設計を見直すことも必要  管理しやすようにやり方を変える．手段と目的が逆転してるように感じるが大事   参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017   Google の巨大レポジトリとブランチ無し運用 - Kato Kazuyoshi [return]   </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (5章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap5/</link>
      <pubDate>Wed, 21 Jun 2017 22:47:39 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap5/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
インフラストラクチャサービス，ツールが満たすべき条件  外部定義を使えるツールを選ぶ  DBに設定を保持するツールはどうすればいいか  設定をyamlなどで構造化してテキストに保存．それを読み込んでAPIを発行，サービスへ設定を反映させる．確実に両者が同一の内容であることを確信するいは逆(サービスからyamlへ)もできる必要がある インポート/エクスポートを使う．(エクスポートした設定情報は大抵は人間が読むようにはできていない．独自のフォーマットで書かれていて容易にパースできない) (本に書いてある例)SeleniumのようなものでGUIを操作する  いずれにしても辛そう．よほどのことがない限りそのようなツールは選択すべきでない  インフラストラクチャがダイナミックだという前提で作られたツールを選ぶ  サービス自身とサービスが管理するものの変化に柔軟に自動的に追従，対処できるもの  ライセンスがクラウド互換になっている製品を選ぶ  ここでは主に柔軟性に関するもの  疎結合をサポートする製品を選ぶ  チーム間でのサービスの共有  チーム間で共有される可能性のあるサービス  モニタリング，CI，バグ追跡(BTS？)，DNS，アーティファクトリポジトリ(構成レジストリ？)  それを使うチームの要件，使われ方の特性などが様々になり，それ自体が小さなパブリックサービスのようにみなせるかもしれない  それぞれサービスレベルやサービス仕様を定めてチームに使ってもらう ふつうにマイクロサービスアーキテクチャの考え方みたい   モニタリング  モニタリングの目標は，必要とする人に必要なときに適切な情報を提供すること  つまり，モニタリングシステムの設計を始める前に想定ユーザを決めるフェーズがあるということ．今までは考えたことなかった  個々のイベントは問題ないが，それが頻発する場合は問題がある可能性がある場合，頻度に関する閾値を設ける (a)日常の仕事を続行する，(b)大声を出して今していることを中断し，対策に乗り出す どちらを取るべきかをすぐに判断できるようなのでなければならない 複数のサーバーに関連性があることを自動的にタギングしなければならない  Zabbixでもネットワークディスカバリ，ローレベルディスカバリ，AgentのUserParameterあたりを使えば自動でタギングできるが，ダッシュボードを動的に生成できないのが辛い  つまりZabbixはInfrastructure as Codeに適していない  DataDogやMackerel(おそらくNewRelicも)はこのへんの考え方が前提になってる Prometheusはこのあたりどうなんだろう．Grafanaと組み合わせれば普通にできそう(それを言えばZabbixでもいいのだが)   サービスディスカバリ  サーバーサイドサービスディスカバリ  ロードバランサが結局ボトルネックになったりする  クライアントサイドサービスディスカバリ  通常，こちらの方がアプリケーションは複雑になる アプリケーションのlocalhostにロードバランサを用意すればいろいろ解決しそう   参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017  </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (5章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap5/</link>
      <pubDate>Wed, 21 Jun 2017 22:47:39 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap5/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
インフラストラクチャサービス，ツールが満たすべき条件  外部定義を使えるツールを選ぶ  DBに設定を保持するツールはどうすればいいか  設定をyamlなどで構造化してテキストに保存．それを読み込んでAPIを発行，サービスへ設定を反映させる．確実に両者が同一の内容であることを確信するいは逆(サービスからyamlへ)もできる必要がある インポート/エクスポートを使う．(エクスポートした設定情報は大抵は人間が読むようにはできていない．独自のフォーマットで書かれていて容易にパースできない) (本に書いてある例)SeleniumのようなものでGUIを操作する  いずれにしても辛そう．よほどのことがない限りそのようなツールは選択すべきでない  インフラストラクチャがダイナミックだという前提で作られたツールを選ぶ  サービス自身とサービスが管理するものの変化に柔軟に自動的に追従，対処できるもの  ライセンスがクラウド互換になっている製品を選ぶ  ここでは主に柔軟性に関するもの  疎結合をサポートする製品を選ぶ  チーム間でのサービスの共有  チーム間で共有される可能性のあるサービス  モニタリング，CI，バグ追跡(BTS？)，DNS，アーティファクトリポジトリ(構成レジストリ？)  それを使うチームの要件，使われ方の特性などが様々になり，それ自体が小さなパブリックサービスのようにみなせるかもしれない  それぞれサービスレベルやサービス仕様を定めてチームに使ってもらう ふつうにマイクロサービスアーキテクチャの考え方みたい   モニタリング  モニタリングの目標は，必要とする人に必要なときに適切な情報を提供すること  つまり，モニタリングシステムの設計を始める前に想定ユーザを決めるフェーズがあるということ．今までは考えたことなかった  個々のイベントは問題ないが，それが頻発する場合は問題がある可能性がある場合，頻度に関する閾値を設ける (a)日常の仕事を続行する，(b)大声を出して今していることを中断し，対策に乗り出す どちらを取るべきかをすぐに判断できるようなのでなければならない 複数のサーバーに関連性があることを自動的にタギングしなければならない  Zabbixでもネットワークディスカバリ，ローレベルディスカバリ，AgentのUserParameterあたりを使えば自動でタギングできるが，ダッシュボードを動的に生成できないのが辛い  つまりZabbixはInfrastructure as Codeに適していない  DataDogやMackerel(おそらくNewRelicも)はこのへんの考え方が前提になってる Prometheusはこのあたりどうなんだろう．Grafanaと組み合わせれば普通にできそう(それを言えばZabbixでもいいのだが)   サービスディスカバリ  サーバーサイドサービスディスカバリ  ロードバランサが結局ボトルネックになったりする  クライアントサイドサービスディスカバリ  通常，こちらの方がアプリケーションは複雑になる アプリケーションのlocalhostにロードバランサを用意すればいろいろ解決しそう   参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017  </description>
    </item>
    
    <item>
      <title>スマートボトルの選定</title>
      <link>http://uyorum.github.io/blog/choosing-smart-water-bottle/</link>
      <pubDate>Sun, 18 Jun 2017 16:56:40 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/choosing-smart-water-bottle/</guid>
      <description>&lt;p&gt;現在使っている水筒(ケータイマグ 600ml)が古くなってきて，新しいものに変えたい．最近Fitbitで水分補給量も記録するようになったが手動入力が面倒なのでこれを自動でやってくれる水筒を選定した&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>スマートボトルの選定</title>
      <link>http://uyorum.github.io/blog/choosing-smart-water-bottle/</link>
      <pubDate>Sun, 18 Jun 2017 16:56:40 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/choosing-smart-water-bottle/</guid>
      <description>&lt;p&gt;現在使っている水筒(ケータイマグ 600ml)が古くなってきて，新しいものに変えたい．最近Fitbitで水分補給量も記録するようになったが手動入力が面倒なのでこれを自動でやってくれる水筒を選定した&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (4章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap4/</link>
      <pubDate>Sat, 17 Jun 2017 18:17:36 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap4/</guid>
      <description>&lt;p&gt;オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．&lt;strong&gt;太字は自分の感想&lt;/strong&gt;， &lt;em&gt;斜字体は本からの引用&lt;/em&gt; ，そのほかは本の要約など．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (4章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap4/</link>
      <pubDate>Sat, 17 Jun 2017 18:17:36 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap4/</guid>
      <description>&lt;p&gt;オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．&lt;strong&gt;太字は自分の感想&lt;/strong&gt;， &lt;em&gt;斜字体は本からの引用&lt;/em&gt; ，そのほかは本の要約など．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (3章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap3/</link>
      <pubDate>Thu, 15 Jun 2017 23:14:55 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap3/</guid>
      <description>オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
ツールの要件  他のツールを連携しやすいこと  コマンドライン引数や環境変数などでの入力，パースしやすい結果出力 設定の外在化  自動実行しやすいこと  冪等性など 失敗したらわかる  周辺のツールとの連携しやすさは意識して考慮に入れてなかった 考え方はすごくよくわかる．UNIX哲学に通じている  構成レジストリ  コンフィグ定義ツールが提供するもの(Chef Server, Ansible Towerなど) Zookeeper/Consul/etcd プログラムによるレジストリエントリの追加，更新，削除をサポートしていること こういうのほしいと前から思っていたけどどうやって実装すればいいか，定義ツールとどう連携させればいいかイメージついてない  軽い構成レジストリ  S3やVCS上のファイル  HTTP等で配布．こうすることで可用性，スケーリングしやすい．管理が単純 頻繁に更新されて複雑になる部分は分割やシャーディングで対応する  こうした場合，例えばAnsibleへはどうやって渡せばいいんだろうか  ansible-playbook実行前にyaml組んでvar_fileなどに渡す  ダイナミックインベントリみたいなことはできなさそう．一回ファイルに吐き出す必要がある？  json組み立ててansible-playbookの--extra-varsオプションに渡す Ansible TowerのAPIでも渡せるかも  Consumer Driven Contract Testing  Itamaeのnode.validate!はまさにこれだと思う1 こんな記事出てきた Consumer-Driven Contracts: A Service Evolution Pattern Pactのようなツールで容易に書けそう   CMDB  CMDBとInfrastructure as Codeは構成管理に対するアプローチが正反対．両者を同一視してはならない  ただしすべてを自動化するならInfrastructure as CodeはCMDBを兼ねることができる．またはInfrastructure as CodeがCMDBも管理することができる ハードウェアも含めてすべてを自動化はけっこうハードル高そう   その他  インフラを完全に管理，自動化するために，やり方を変えるだけでなく自動化しやすいようにタスクそのものを見直すメンタルを忘れてはいけない  以上</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (3章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap3/</link>
      <pubDate>Thu, 15 Jun 2017 23:14:55 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap3/</guid>
      <description>オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
ツールの要件  他のツールを連携しやすいこと  コマンドライン引数や環境変数などでの入力，パースしやすい結果出力 設定の外在化  自動実行しやすいこと  冪等性など 失敗したらわかる  周辺のツールとの連携しやすさは意識して考慮に入れてなかった 考え方はすごくよくわかる．UNIX哲学に通じている  構成レジストリ  コンフィグ定義ツールが提供するもの(Chef Server, Ansible Towerなど) Zookeeper/Consul/etcd プログラムによるレジストリエントリの追加，更新，削除をサポートしていること こういうのほしいと前から思っていたけどどうやって実装すればいいか，定義ツールとどう連携させればいいかイメージついてない  軽い構成レジストリ  S3やVCS上のファイル  HTTP等で配布．こうすることで可用性，スケーリングしやすい．管理が単純 頻繁に更新されて複雑になる部分は分割やシャーディングで対応する  こうした場合，例えばAnsibleへはどうやって渡せばいいんだろうか  ansible-playbook実行前にyaml組んでvar_fileなどに渡す  ダイナミックインベントリみたいなことはできなさそう．一回ファイルに吐き出す必要がある？  json組み立ててansible-playbookの--extra-varsオプションに渡す Ansible TowerのAPIでも渡せるかも  Consumer Driven Contract Testing  Itamaeのnode.validate!はまさにこれだと思う1 こんな記事出てきた Consumer-Driven Contracts: A Service Evolution Pattern Pactのようなツールで容易に書けそう   CMDB  CMDBとInfrastructure as Codeは構成管理に対するアプローチが正反対．両者を同一視してはならない  ただしすべてを自動化するならInfrastructure as CodeはCMDBを兼ねることができる．またはInfrastructure as CodeがCMDBも管理することができる ハードウェアも含めてすべてを自動化はけっこうハードル高そう   その他  インフラを完全に管理，自動化するために，やり方を変えるだけでなく自動化しやすいようにタスクそのものを見直すメンタルを忘れてはいけない  以上</description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (2章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap2/</link>
      <pubDate>Mon, 12 Jun 2017 20:48:25 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap2/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
ダイナミックインフラストラクチャの要件  NISTのクラウドの要件より広い．  「オンプレミスで，ただひとつのシステムを稼動させるためのインフラ」も考慮に入れているからだろう   プラットフォームから提供されるリソース  計算リソース ストレージリソース  ブロックストレージ オブジェクトストレージ ネットワーク化されたファイルシステム  NFS，SMB  これらのテクノロジは，サーバーが頻繁に追加，削除されるような環境にはうまく適合しない  GlusterFS，HDFS，Ceph  上記の課題に対応できるよう設計されているが，自分の環境でそれがうまくいっていることをきちんとテストすることが重要 代わりにアプリケーションレベルやブロックレベルのレプリケーションで事足りる場合もある    ネットワークリソース  特定のデバイスが高価過ぎて，チームがテストインスタンスを確保できない場合がある．そのような状況に置かれたチームは，優先順位を考えてもっと安いデバイスを使うようにすべきだ  確かに，結局のところ同じハードを同じだけ用意しないとテストできないのだが，そのために使うデバイスを安いものにしろ，という言説は初めて見た．だいたいは仮想化してお茶を濁すのに．    独自クラウドを構築するためのトータルコスト  既存のインフラ，データセンター，知識にかけたコストも自前のホスティングを続ける理由としてよく挙げられる．(中略) しかし，これはサンクコストの呪縛というものだ．  クラウドのポータビリティ  クラウドインフラへの移行を計画するときによく浮上する要件のひとつに，ひとつのクラウドベンダーによる囲い込みを避けるというものがある．(中略) しかし，この要件に時間と金を注ぎ込みすぎないよう注意しなければならない  確かに，クラウドの一部の機能をサードパーティ製のツールで置き換えたところで依然として移行のコストは大きいし，だいたいの場合は運用のコストが上がる あるクラウドでのやり方が(将来にわたって)それが別のクラウドでそのまま利用できるとは限らない  例えば，TerraformでEC2とGCEにインスタンスを作るだけで全く文法が違う(Terraformの批判をしているわけではない) クラウドやツールが将来仕様変更をするかもしれないし  サードパーティ製のものを使うことでよりよりワークフローを得られる可能性がある場合は検討すべき(CodeCommitとCodeBuildの代わりにGithubとTravisCIとか)  自動テストプロセスを継続して維持・使用することで，自信をもって移行を実施できるようにしておくのが現実的な方策  クラウドと仮想マシンに対するマシンレベルの共感  そのプラットフォームで最大のパフォーマンスを引き出すための話？ 必要性は分かるが，ポータビリティとは真逆の話に見える  あまりにそのクラウドに最適化してしまうとポータビリティを落とす要因になりそう  オンプレの場合でも，構成に応じて最適化しつつそれらを管理するのは大変そう．妥協して汎用的なサーバーを横に並べる形になりそう  参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017  </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (2章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap2/</link>
      <pubDate>Mon, 12 Jun 2017 20:48:25 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap2/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
ダイナミックインフラストラクチャの要件  NISTのクラウドの要件より広い．  「オンプレミスで，ただひとつのシステムを稼動させるためのインフラ」も考慮に入れているからだろう   プラットフォームから提供されるリソース  計算リソース ストレージリソース  ブロックストレージ オブジェクトストレージ ネットワーク化されたファイルシステム  NFS，SMB  これらのテクノロジは，サーバーが頻繁に追加，削除されるような環境にはうまく適合しない  GlusterFS，HDFS，Ceph  上記の課題に対応できるよう設計されているが，自分の環境でそれがうまくいっていることをきちんとテストすることが重要 代わりにアプリケーションレベルやブロックレベルのレプリケーションで事足りる場合もある    ネットワークリソース  特定のデバイスが高価過ぎて，チームがテストインスタンスを確保できない場合がある．そのような状況に置かれたチームは，優先順位を考えてもっと安いデバイスを使うようにすべきだ  確かに，結局のところ同じハードを同じだけ用意しないとテストできないのだが，そのために使うデバイスを安いものにしろ，という言説は初めて見た．だいたいは仮想化してお茶を濁すのに．    独自クラウドを構築するためのトータルコスト  既存のインフラ，データセンター，知識にかけたコストも自前のホスティングを続ける理由としてよく挙げられる．(中略) しかし，これはサンクコストの呪縛というものだ．  クラウドのポータビリティ  クラウドインフラへの移行を計画するときによく浮上する要件のひとつに，ひとつのクラウドベンダーによる囲い込みを避けるというものがある．(中略) しかし，この要件に時間と金を注ぎ込みすぎないよう注意しなければならない  確かに，クラウドの一部の機能をサードパーティ製のツールで置き換えたところで依然として移行のコストは大きいし，だいたいの場合は運用のコストが上がる あるクラウドでのやり方が(将来にわたって)それが別のクラウドでそのまま利用できるとは限らない  例えば，TerraformでEC2とGCEにインスタンスを作るだけで全く文法が違う(Terraformの批判をしているわけではない) クラウドやツールが将来仕様変更をするかもしれないし  サードパーティ製のものを使うことでよりよりワークフローを得られる可能性がある場合は検討すべき(CodeCommitとCodeBuildの代わりにGithubとTravisCIとか)  自動テストプロセスを継続して維持・使用することで，自信をもって移行を実施できるようにしておくのが現実的な方策  クラウドと仮想マシンに対するマシンレベルの共感  そのプラットフォームで最大のパフォーマンスを引き出すための話？ 必要性は分かるが，ポータビリティとは真逆の話に見える  あまりにそのクラウドに最適化してしまうとポータビリティを落とす要因になりそう  オンプレの場合でも，構成に応じて最適化しつつそれらを管理するのは大変そう．妥協して汎用的なサーバーを横に並べる形になりそう  参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017  </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (1章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap1/</link>
      <pubDate>Sun, 11 Jun 2017 19:05:42 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap1/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
Infrastructure as Codeの目標  ざっくり言うと「(頻繁な)変化に柔軟に対応できるようになること」ということかなと思った そのために  システム変更が日常茶飯事の出来事になること 失敗を完全に防ぐという前提は捨てる．失敗しても素早く修正できるようになることを目指す 反復的なタスクは自動化すること 継続的な改善をすること  会議やドキュメントでソリューションを論ずることなく，実装，テスト，計測を通じてソリューションの効果が証明できるようになること  Infrastructure as Codeでこれを目指す，というのがピンと来なかった   課題  サーバースプロール，構成ドリフト，スノーフレークサーバーは自分の環境ではほとんどないかな  いちおうChefを使っている ロールごとにVMを作成して役割が混ざらないようにしている  オートメーション恐怖症…これはある  サーバーに統一性がない→オートメーションにより何かが壊れないかが心配→オートメーションツールの外で変更を加える→… の悪循環 この循環から抜けるには「自動化された変更」のリリースプロセスの確立とテストの充実が必要になると最近は考えている  「この変更」を「この方法」で適用するのは安全である，と自動的に言えるようになればいい   ペットから家畜へ  数年前からよく聞くようになった サーバ名にテーマを設け，自分がプロビジョニングした新しいサーバーの名前をじっくり考えていた時代が懐しい．しかし，担当するすべてのサーバーを手作業で調整し，サーバーのご期限をうかがわなけれあならなかった時代は懐しくない  おもしろい    統一的なシステム  一部のサーバーでより大きなディスクが必要になった場合  すべてのサーバーを同じように拡張する xl-file-serverのような新しいロールを追加する  自分だと深く考えずに(ロールを分けずに)そのサーバーだけ拡張してしまいそうだと思った(ディスクサイズだけ変数化しておけばいいじゃん)  その些細な差異が積み重なって管理システムと人に負荷を与えることになる．気をつけたい   反復的なシステム  「パーティションの分割」のような些細なタスクであろうとも，手動でやってしまうと差異が生じる可能性がある．  サイズ，ファイルシステム，そのパラメータ etc.  スクリプトで実行できるシステムはかならずスクリプトにする  そして，将来同様のタスクをするとになったときにそのスクリプトを使う ←これが難しい．スクリプトを書くだけでなく管理システムに組み込まなければならない  スクリプトにするのが難しい場合は問題を掘り下げて，役に立つテクニックやツールがないか，別の方法がないかを検討する  継続的にサービスを利用可能状態に保つ  永続化が必要なデータの定義を広げることが大切．通常はアプリケーションの構成/設定，ログファイルなども保護対象に含める  サーバーを家畜のように扱うことを前提に，サーバー上のほとんどの情報はいつ失われてもよい状態にしておくということか   参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017  </description>
    </item>
    
    <item>
      <title>Infrastructure as Code 感想 (1章)</title>
      <link>http://uyorum.github.io/blog/infrastructure-as-code-chap1/</link>
      <pubDate>Sun, 11 Jun 2017 19:05:42 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/infrastructure-as-code-chap1/</guid>
      <description> オライリーの「Infrastructure as Code」を読んで思ったことや自分的メモをまとめておく．太字は自分の感想， 斜字体は本からの引用 ，そのほかは本の要約など．
Infrastructure as Codeの目標  ざっくり言うと「(頻繁な)変化に柔軟に対応できるようになること」ということかなと思った そのために  システム変更が日常茶飯事の出来事になること 失敗を完全に防ぐという前提は捨てる．失敗しても素早く修正できるようになることを目指す 反復的なタスクは自動化すること 継続的な改善をすること  会議やドキュメントでソリューションを論ずることなく，実装，テスト，計測を通じてソリューションの効果が証明できるようになること  Infrastructure as Codeでこれを目指す，というのがピンと来なかった   課題  サーバースプロール，構成ドリフト，スノーフレークサーバーは自分の環境ではほとんどないかな  いちおうChefを使っている ロールごとにVMを作成して役割が混ざらないようにしている  オートメーション恐怖症…これはある  サーバーに統一性がない→オートメーションにより何かが壊れないかが心配→オートメーションツールの外で変更を加える→… の悪循環 この循環から抜けるには「自動化された変更」のリリースプロセスの確立とテストの充実が必要になると最近は考えている  「この変更」を「この方法」で適用するのは安全である，と自動的に言えるようになればいい   ペットから家畜へ  数年前からよく聞くようになった サーバ名にテーマを設け，自分がプロビジョニングした新しいサーバーの名前をじっくり考えていた時代が懐しい．しかし，担当するすべてのサーバーを手作業で調整し，サーバーのご期限をうかがわなけれあならなかった時代は懐しくない  おもしろい    統一的なシステム  一部のサーバーでより大きなディスクが必要になった場合  すべてのサーバーを同じように拡張する xl-file-serverのような新しいロールを追加する  自分だと深く考えずに(ロールを分けずに)そのサーバーだけ拡張してしまいそうだと思った(ディスクサイズだけ変数化しておけばいいじゃん)  その些細な差異が積み重なって管理システムと人に負荷を与えることになる．気をつけたい   反復的なシステム  「パーティションの分割」のような些細なタスクであろうとも，手動でやってしまうと差異が生じる可能性がある．  サイズ，ファイルシステム，そのパラメータ etc.  スクリプトで実行できるシステムはかならずスクリプトにする  そして，将来同様のタスクをするとになったときにそのスクリプトを使う ←これが難しい．スクリプトを書くだけでなく管理システムに組み込まなければならない  スクリプトにするのが難しい場合は問題を掘り下げて，役に立つテクニックやツールがないか，別の方法がないかを検討する  継続的にサービスを利用可能状態に保つ  永続化が必要なデータの定義を広げることが大切．通常はアプリケーションの構成/設定，ログファイルなども保護対象に含める  サーバーを家畜のように扱うことを前提に，サーバー上のほとんどの情報はいつ失われてもよい状態にしておくということか   参考文献  Kief Morris, Infrastructure as Code クラウドにおけるサーバ管理の原則とプラクティス, 長尾高弘訳, オライリー・ジャパン, 2017  </description>
    </item>
    
    <item>
      <title>Home AssistantとAmazon Dash Buttonを連携させる</title>
      <link>http://uyorum.github.io/blog/home-assistant-with-dash-button/</link>
      <pubDate>Sat, 10 Jun 2017 20:20:04 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/home-assistant-with-dash-button/</guid>
      <description>&lt;p&gt;Amazon Dash Button間違った使い方ができることで有名だが，Amazon Dash ButtonからHome Assistantでアクションをキックできるようにしてみる．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Home AssistantとAmazon Dash Buttonを連携させる</title>
      <link>http://uyorum.github.io/blog/home-assistant-with-dash-button/</link>
      <pubDate>Sat, 10 Jun 2017 20:20:04 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/home-assistant-with-dash-button/</guid>
      <description>&lt;p&gt;Amazon Dash Button間違った使い方ができることで有名だが，Amazon Dash ButtonからHome Assistantでアクションをキックできるようにしてみる．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Home Assistantで人感センサーを使って照明を自動点灯する</title>
      <link>http://uyorum.github.io/blog/home-assistant-gpio/</link>
      <pubDate>Sun, 23 Apr 2017 21:33:54 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/home-assistant-gpio/</guid>
      <description>&lt;p&gt;Home Assistantで人感センサーを使って自宅の廊下の電球を点灯/消灯するシステムを組んでみる．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Home Assistantで人感センサーを使って照明を自動点灯する</title>
      <link>http://uyorum.github.io/blog/home-assistant-gpio/</link>
      <pubDate>Sun, 23 Apr 2017 21:33:54 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/home-assistant-gpio/</guid>
      <description>&lt;p&gt;Home Assistantで人感センサーを使って自宅の廊下の電球を点灯/消灯するシステムを組んでみる．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Home Assistantでつくるホームオートメーション(導入編)</title>
      <link>http://uyorum.github.io/blog/home-assistant-install/</link>
      <pubDate>Sat, 22 Apr 2017 21:48:00 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/home-assistant-install/</guid>
      <description>&lt;p&gt;ホームオートメーション/スマートホーム化を実現できるOSSのHome Asssitantについて&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Home Assistantでつくるホームオートメーション(導入編)</title>
      <link>http://uyorum.github.io/blog/home-assistant-install/</link>
      <pubDate>Sat, 22 Apr 2017 21:48:00 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/home-assistant-install/</guid>
      <description>&lt;p&gt;ホームオートメーション/スマートホーム化を実現できるOSSのHome Asssitantについて&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Erato Audio Apollo7 レビュー</title>
      <link>http://uyorum.github.io/blog/apollo7-1/</link>
      <pubDate>Sun, 09 Oct 2016 17:39:14 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/apollo7-1/</guid>
      <description>Erato Audio社の完全ワイヤレスイヤホンApollo7を買って1週間ほど使ったので使用感とかレビューを書いておきます．
なぜ今買ったか 完全ワイヤレスイヤホンという分野を知ったのは2014年にKickstarterでEARINが発表されたときでした． そのときは非常に気になっていたのですが，スペック的にいくつか気になるところもあり，まだ新しい分野でもあったので買うのはもう少し製品が成熟してからにしようと思って手を出しませんでした． 以降はこの分野については特にウォッチはせずに忘れていたのですが，最近AppleからAirPodsが発表されたのを見て思い出して再度調べてみたのがきっかけでした． いくつかのメーカーから同様の製品が発売されていることを知り，その中でよさそうなApolloo7を選択しました．
なぜApollo7を選択したか とりあえず2ちゃんねるの該当スレで評判を見ていきました． ざっと眺めたところ，スレ内ではEARIN，Apollo7，The Dashがよく話題に挙がる機種のようでした． 各機種の特徴と評判は以下の通り．
EARIN  BA型ドライバを搭載 人の多いところで接続が切れやすいという発言をよく見かけた そもそもかつて見送った機種  The Dash  ストレージ内蔵，フィットネストラッカー搭載，トランスペアレントモード搭載と，他の機種と比べて多機能  個人的には前半2つの機能はこの手の機種に求めない  本体とケースが大きい  Apollo7  人が多いところでも接続が切れにくいという発言をよく見かけた 自分が求めている必要最小限の機能 デザインがよい 9/30に国内代理店が取扱いを開始するので保証などを受けやすい  以上の点から検討した結果，Apollo7を選択しました． 国内だとeイヤホンで試聴できるですが，所詮Bluetoothだし音質はそれほど重視していなかったので試聴せずにヨドバシドットコムにて購入．
使い勝手 各イヤホンは本体にボタンを搭載しており，このボタンを押すことで本体またはスマホを操作します． 各イヤホンにはLまたはRと印字されており，左右どちら用かはあらかじめ決まっているようです．
初期セットアップ  左右どちらかのイヤホン(以降，右耳とする)のボタンを長押しする 「Power on」と声が流れるが引き続き長押しし続ける 「Pairing」と声が流れるのでスマホを操作しペアリングする 「Phone connected」と声が流れる(このイヤホンがスマホと接続される) 左耳のイヤホンのボタンを長押しする 「Headset connected」と両耳から流れる(このイヤホンは右耳のイヤホンと接続される)  再度使うとき  イヤホンをケースから取り出す 右耳のイヤホンのボタンを長押しする(「Power on」と流れる) しばらくするとスマホと接続される(「Phone connected」と流れる) 左耳のイヤホンのボタンを長押しする(「Power on」と流れる) しばらくすると右耳と接続される(「Headset connected」と両耳から流れる)  レビュー いずれもNexus5で使用していて気付いた点です．ペアリングする機種によって接続の切れにくさなどは異なる可能性があります．
いい点  やっぱり完全ワイヤレスは便利
鞄の中でケーブルがからまることがない，使用中にケーブルがひっかかることがない．かなり便利です． フィット感がいい</description>
    </item>
    
    <item>
      <title>Erato Audio Apollo7 レビュー</title>
      <link>http://uyorum.github.io/blog/apollo7-1/</link>
      <pubDate>Sun, 09 Oct 2016 17:39:14 +0900</pubDate>
      
      <guid>http://uyorum.github.io/blog/apollo7-1/</guid>
      <description>Erato Audio社の完全ワイヤレスイヤホンApollo7を買って1週間ほど使ったので使用感とかレビューを書いておきます．
なぜ今買ったか 完全ワイヤレスイヤホンという分野を知ったのは2014年にKickstarterでEARINが発表されたときでした． そのときは非常に気になっていたのですが，スペック的にいくつか気になるところもあり，まだ新しい分野でもあったので買うのはもう少し製品が成熟してからにしようと思って手を出しませんでした． 以降はこの分野については特にウォッチはせずに忘れていたのですが，最近AppleからAirPodsが発表されたのを見て思い出して再度調べてみたのがきっかけでした． いくつかのメーカーから同様の製品が発売されていることを知り，その中でよさそうなApolloo7を選択しました．
なぜApollo7を選択したか とりあえず2ちゃんねるの該当スレで評判を見ていきました． ざっと眺めたところ，スレ内ではEARIN，Apollo7，The Dashがよく話題に挙がる機種のようでした． 各機種の特徴と評判は以下の通り．
EARIN  BA型ドライバを搭載 人の多いところで接続が切れやすいという発言をよく見かけた そもそもかつて見送った機種  The Dash  ストレージ内蔵，フィットネストラッカー搭載，トランスペアレントモード搭載と，他の機種と比べて多機能  個人的には前半2つの機能はこの手の機種に求めない  本体とケースが大きい  Apollo7  人が多いところでも接続が切れにくいという発言をよく見かけた 自分が求めている必要最小限の機能 デザインがよい 9/30に国内代理店が取扱いを開始するので保証などを受けやすい  以上の点から検討した結果，Apollo7を選択しました． 国内だとeイヤホンで試聴できるですが，所詮Bluetoothだし音質はそれほど重視していなかったので試聴せずにヨドバシドットコムにて購入．
使い勝手 各イヤホンは本体にボタンを搭載しており，このボタンを押すことで本体またはスマホを操作します． 各イヤホンにはLまたはRと印字されており，左右どちら用かはあらかじめ決まっているようです．
初期セットアップ  左右どちらかのイヤホン(以降，右耳とする)のボタンを長押しする 「Power on」と声が流れるが引き続き長押しし続ける 「Pairing」と声が流れるのでスマホを操作しペアリングする 「Phone connected」と声が流れる(このイヤホンがスマホと接続される) 左耳のイヤホンのボタンを長押しする 「Headset connected」と両耳から流れる(このイヤホンは右耳のイヤホンと接続される)  再度使うとき  イヤホンをケースから取り出す 右耳のイヤホンのボタンを長押しする(「Power on」と流れる) しばらくするとスマホと接続される(「Phone connected」と流れる) 左耳のイヤホンのボタンを長押しする(「Power on」と流れる) しばらくすると右耳と接続される(「Headset connected」と両耳から流れる)  レビュー いずれもNexus5で使用していて気付いた点です．ペアリングする機種によって接続の切れにくさなどは異なる可能性があります．
いい点  やっぱり完全ワイヤレスは便利
鞄の中でケーブルがからまることがない，使用中にケーブルがひっかかることがない．かなり便利です． フィット感がいい</description>
    </item>
    
  </channel>
</rss>